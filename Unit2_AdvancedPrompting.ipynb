{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba92b198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "%pip install python-dotenv --upgrade --quiet langchain langchain-groq\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "if \"GROQ_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API Key: \")\n",
    "\n",
    "# Using Llama3.1-8b (Small/Fast) to demonstrate logic failures\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a70d3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STANDARD (Llama3.1-8b) ---\n",
      "To find out how many tennis balls Roger has now, we need to add the initial number of tennis balls he had (5) to the number of tennis balls he bought (2 cans * 3 tennis balls per can).\n",
      "\n",
      "2 cans * 3 tennis balls per can = 6 tennis balls\n",
      "\n",
      "Now, let's add the initial number of tennis balls (5) to the number of tennis balls he bought (6):\n",
      "\n",
      "5 + 6 = 11\n",
      "\n",
      "So, Roger now has 11 tennis balls.\n"
     ]
    }
   ],
   "source": [
    "question = \"Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many does he have now?\"\n",
    "\n",
    "# 1. Standard Prompt (Direct Answer)\n",
    "prompt_standard = f\"Answer this question: {question}\"\n",
    "print(\"--- STANDARD (Llama3.1-8b) ---\")\n",
    "print(llm.invoke(prompt_standard).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dd65b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Chain of Thought (Llama3.1-8b) ---\n",
      "To find out how many tennis balls Roger has now, we need to follow these steps:\n",
      "\n",
      "1. Roger already has 5 tennis balls.\n",
      "2. He buys 2 more cans of tennis balls. Each can has 3 tennis balls, so he buys 2 x 3 = 6 more tennis balls.\n",
      "3. Now, we add the tennis balls he already had (5) to the new tennis balls he bought (6). 5 + 6 = 11\n",
      "\n",
      "So, Roger now has 11 tennis balls.\n"
     ]
    }
   ],
   "source": [
    "# 2. CoT Prompt (Magic Phrase)\n",
    "prompt_cot = f\"Answer this question. Let's think step by step. {question}\"\n",
    "\n",
    "print(\"--- Chain of Thought (Llama3.1-8b) ---\")\n",
    "print(llm.invoke(prompt_cot).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4371aa3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "%pip install python-dotenv --upgrade --quiet langchain langchain-groq\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "if \"GROQ_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API Key: \")\n",
    "\n",
    "# Using Llama3.1-8b\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0.7) # Creativity needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ea2d4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tree of Thoughts (ToT) Result ---\n",
      "As a child psychologist, I would recommend **Solution 3: The \"Veggie Face\" Game** as the most sustainable approach to encourage a 5-year-old to eat vegetables. Here's why:\n",
      "\n",
      "1. **Encourages engagement**: This solution involves creating a fun and interactive experience by transforming vegetables into silly faces on the plate. This encourages the child to engage with the food, view it as a game, and take an active role in mealtime.\n",
      "2. **Fosters creativity**: The \"Veggie Face\" game allows children to express their creativity and imagination, which is essential for cognitive development and problem-solving skills.\n",
      "3. **Builds confidence**: By making a fun face using vegetables, children feel a sense of accomplishment and pride in their creation. This confidence boost can translate to other areas of life, including trying new foods and developing healthy eating habits.\n",
      "4. **Non-bribery approach**: Unlike other solutions that might involve hiding vegetables in foods or using sauces to mask flavors, the \"Veggie Face\" game is a non-bribery approach that encourages children to appreciate the taste and texture of vegetables.\n",
      "5. **Long-term effects**: This solution can lead to long-term effects, such as developing a positive relationship with vegetables and a willingness to try new foods. Children are more likely to adopt healthy eating habits if they enjoy the process of mealtime and feel engaged in the experience.\n",
      "6. **Flexibility**: The \"Veggie Face\" game can be adapted to different situations and preferences. Children can create their own faces, use different shapes and colors, and experiment with various sauces and dips.\n",
      "\n",
      "In contrast, while Solution 1 and Solution 2 are creative and engaging, they might be more prone to bribery if not implemented carefully. For example, if a child is only eating vegetables because they are presented in a fun way, but not because they enjoy the taste, it may not lead to long-term healthy eating habits.\n",
      "\n",
      "Overall, the \"Veggie Face\" game is a sustainable approach that encourages children to engage with vegetables, fosters creativity and confidence, and promotes healthy eating habits without relying on bribery or gimmicks.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "problem = \"How can I get my 5-year-old to eat vegetables?\"\n",
    "\n",
    "# Step 1: The Branch Generator\n",
    "prompt_branch = ChatPromptTemplate.from_template(\n",
    "    \"Problem: {problem}. Give me one unique, creative solution. Solution {id}:\"\n",
    ")\n",
    "\n",
    "branches = RunnableParallel(\n",
    "    sol1=prompt_branch.partial(id=\"1\") | llm | StrOutputParser(),\n",
    "    sol2=prompt_branch.partial(id=\"2\") | llm | StrOutputParser(),\n",
    "    sol3=prompt_branch.partial(id=\"3\") | llm | StrOutputParser(),\n",
    ")\n",
    "\n",
    "# Step 2: The Judge\n",
    "prompt_judge = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    I have three proposed solutions for: '{problem}'\n",
    "    \n",
    "    1: {sol1}\n",
    "    2: {sol2}\n",
    "    3: {sol3}\n",
    "    \n",
    "    Act as a Child Psychologist. Pick the most sustainable one (not bribery) and explain why.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Chain: Input -> Branches -> Judge -> Output\n",
    "tot_chain = (\n",
    "    RunnableParallel(problem=RunnableLambda(lambda x: x), branches=branches)\n",
    "    | (lambda x: {**x[\"branches\"], \"problem\": x[\"problem\"]}) \n",
    "    | prompt_judge\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"--- Tree of Thoughts (ToT) Result ---\")\n",
    "print(tot_chain.invoke(problem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "894940b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Graph of Thoughts (GoT) Result ---\n",
      "\"Echoes of Eternity\" is a thrilling time-travel epic that weaves together science, romance, and horror. When brilliant physicist and temporal engineer, Emma Taylor, accidentally activates her latest invention, a mysterious time loop forms, catapulting her back to the 19th century, where she becomes entangled with a dashing young nobleman, Alexander, who is searching for a lost love. But as Emma tries to navigate the complexities of her newfound feelings for Alexander, she begins to realize that their time together is not just a coincidence - it's a desperate attempt by the fabric of time itself to prevent a catastrophic event that will unleash a malevolent entity from the past, a vengeful spirit known only as \"The Devourer.\" As the entity begins to stalk Emma and Alexander, threatening to shatter the very fabric of reality, they must navigate the treacherous landscape of time travel, confronting the darkness of their own pasts and the terror of an unknown future, all while racing against the clock to prevent the entity's return and restore balance to the timeline.\n"
     ]
    }
   ],
   "source": [
    "# 1. The Generator (Divergence)\n",
    "prompt_draft = ChatPromptTemplate.from_template(\n",
    "    \"Write a 1-sentence movie plot about: {topic}. Genre: {genre}.\"\n",
    ")\n",
    "\n",
    "drafts = RunnableParallel(\n",
    "    draft_scifi=prompt_draft.partial(genre=\"Sci-Fi\") | llm | StrOutputParser(),\n",
    "    draft_romance=prompt_draft.partial(genre=\"Romance\") | llm | StrOutputParser(),\n",
    "    draft_horror=prompt_draft.partial(genre=\"Horror\") | llm | StrOutputParser(),\n",
    ")\n",
    "\n",
    "# 2. The Aggregator (Convergence)\n",
    "prompt_combine = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    I have three movie ideas for the topic '{topic}':\n",
    "    1. Sci-Fi: {draft_scifi}\n",
    "    2. Romance: {draft_romance}\n",
    "    3. Horror: {draft_horror}\n",
    "    \n",
    "    Your task: Create a new Mega-Movie that combines the TECHNOLOGY of Sci-Fi, the PASSION of Romance, and the FEAR of Horror.\n",
    "    Write one paragraph.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# 3. The Chain\n",
    "got_chain = (\n",
    "    RunnableParallel(topic=RunnableLambda(lambda x: x), drafts=drafts)\n",
    "    | (lambda x: {**x[\"drafts\"], \"topic\": x[\"topic\"]}) \n",
    "    | prompt_combine\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"--- Graph of Thoughts (GoT) Result ---\")\n",
    "print(got_chain.invoke(\"Time Travel\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455cb724",
   "metadata": {},
   "source": [
    "## 4. Summary & Comparison Table\n",
    "\n",
    "| Method | Structure | Best For... | Cost/Latency |\n",
    "|--------|-----------|-------------|--------------|\n",
    "| **Simple Prompt** | Input -> Output | Simple facts, summaries | ⭐ Low |\n",
    "| **CoT (Chain)** | Input -> Steps -> Output | Math, Logic, Debugging | ⭐⭐ Med |\n",
    "| **ToT (Tree)** | Input -> 3x Branches -> Select -> Output | Strategic decisions, Brainstorming | ⭐⭐⭐ High | \n",
    "| **GoT (Graph)** | Input -> Branch -> Mix/Aggregate -> Output | Creative Writing, Research Synthesis | ⭐⭐⭐⭐ V. High |\n",
    "\n",
    "**Recommendation:** Start with CoT. Only use ToT/GoT if CoT fails."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
